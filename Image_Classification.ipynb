{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cattle dinosaur apple   boy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple',\n",
      " 'aquarium_fish',\n",
      " 'baby',\n",
      " 'bear',\n",
      " 'beaver',\n",
      " 'bed',\n",
      " 'bee',\n",
      " 'beetle',\n",
      " 'bicycle',\n",
      " 'bottle',\n",
      " 'bowl',\n",
      " 'boy',\n",
      " 'bridge',\n",
      " 'bus',\n",
      " 'butterfly',\n",
      " 'camel',\n",
      " 'can',\n",
      " 'castle',\n",
      " 'caterpillar',\n",
      " 'cattle',\n",
      " 'chair',\n",
      " 'chimpanzee',\n",
      " 'clock',\n",
      " 'cloud',\n",
      " 'cockroach',\n",
      " 'couch',\n",
      " 'crab',\n",
      " 'crocodile',\n",
      " 'cup',\n",
      " 'dinosaur',\n",
      " 'dolphin',\n",
      " 'elephant',\n",
      " 'flatfish',\n",
      " 'forest',\n",
      " 'fox',\n",
      " 'girl',\n",
      " 'hamster',\n",
      " 'house',\n",
      " 'kangaroo',\n",
      " 'keyboard',\n",
      " 'lamp',\n",
      " 'lawn_mower',\n",
      " 'leopard',\n",
      " 'lion',\n",
      " 'lizard',\n",
      " 'lobster',\n",
      " 'man',\n",
      " 'maple_tree',\n",
      " 'motorcycle',\n",
      " 'mountain',\n",
      " 'mouse',\n",
      " 'mushroom',\n",
      " 'oak_tree',\n",
      " 'orange',\n",
      " 'orchid',\n",
      " 'otter',\n",
      " 'palm_tree',\n",
      " 'pear',\n",
      " 'pickup_truck',\n",
      " 'pine_tree',\n",
      " 'plain',\n",
      " 'plate',\n",
      " 'poppy',\n",
      " 'porcupine',\n",
      " 'possum',\n",
      " 'rabbit',\n",
      " 'raccoon',\n",
      " 'ray',\n",
      " 'road',\n",
      " 'rocket',\n",
      " 'rose',\n",
      " 'sea',\n",
      " 'seal',\n",
      " 'shark',\n",
      " 'shrew',\n",
      " 'skunk',\n",
      " 'skyscraper',\n",
      " 'snail',\n",
      " 'snake',\n",
      " 'spider',\n",
      " 'squirrel',\n",
      " 'streetcar',\n",
      " 'sunflower',\n",
      " 'sweet_pepper',\n",
      " 'table',\n",
      " 'tank',\n",
      " 'telephone',\n",
      " 'television',\n",
      " 'tiger',\n",
      " 'tractor',\n",
      " 'train',\n",
      " 'trout',\n",
      " 'tulip',\n",
      " 'turtle',\n",
      " 'wardrobe',\n",
      " 'whale',\n",
      " 'willow_tree',\n",
      " 'wolf',\n",
      " 'woman',\n",
      " 'worm']\n",
      "Number of classes: 100\n",
      "Where's the beaver?\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Pytorch\\Section2\\prep.py\n",
    "\"\"\"\n",
    "Get and prepare the CIFAR100 dataset and its classes\n",
    "To train a custom CNN Beaver detector.\n",
    "\"\"\"\n",
    "#  to generate reproducible random numbers we give hard coded numbers\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "#  Transforms are used for Common Image Transformations and utils to make a grid of images\n",
    "from torchvision import transforms, utils\n",
    "# Import dataset named CIFAR100\n",
    "from torchvision.datasets import CIFAR100\n",
    "# Combines dataset and sampler\n",
    "from torch.utils.data import DataLoader\n",
    "# to plot data\n",
    "import matplotlib.pyplot as plt\n",
    "#  for Scientific calculations\n",
    "import numpy as np\n",
    "#  Used for serializing and deserializing a python object\n",
    "import pickle\n",
    "\n",
    "def get_data(batch_size=4, transform=None):\n",
    "    \"\"\"\n",
    "    Get training and test sets ready to use\n",
    "    with the network.\n",
    "\n",
    "    Return also the class names/labels that are\n",
    "    available in the dataset.\n",
    "\n",
    "    batch_size   a number of samples to split our dataset into\n",
    "    transform   transform.Compose, list of transforms to do on each image\n",
    "    \"\"\"\n",
    "    trainset = CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\t# Data loader. Combines a dataset and a sampler, and provides single  or multi process iterators over the dataset.\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    testset = CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # After data has been downloaded we can access the mapping\n",
    "    # between class indexes and the name of the classes.\n",
    "    classes=pickle.load(open('./data/cifar-100-python/meta', 'rb'))\n",
    "    classes=classes['fine_label_names']\n",
    "\n",
    "    return trainloader, testloader, classes\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    Show images.\n",
    "    \"\"\"\n",
    "    # Since we've already transformed\n",
    "    # our images we need to \"undo\" it\n",
    "    # simple to make them more visible.\n",
    "\t# to get the image back in [0,1] range,use,\n",
    "\t#image = ((image * std) + mean)\n",
    "    img = img / 2 + 0.5\n",
    "\t# convert to numpy\n",
    "    npimg = img.numpy()\n",
    "\t# permute axes according to the values\n",
    "    npimg=np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "\n",
    "def show(trainloader,classes,batch_size=4):\n",
    "    \"\"\"\n",
    "    Show some images from training set.\n",
    "    \"\"\"\n",
    "    # Turn data loader to interator,so\n",
    "    # To get some images.\n",
    "    dataiter = iter(trainloader)\n",
    "    # Get a single batch (4 images).\n",
    "    images, labels = dataiter.next()\n",
    "    # Show the name of the classes for those images.\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "    # Show images.\n",
    "    imshow(utils.make_grid(images))\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [ 1, 1].\n",
    "beavernet_transform = transforms.Compose([\n",
    "#  transform image to tensor\n",
    " transforms.ToTensor(),\n",
    "#  normalize mean, standard deviation\n",
    "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "alexnet_transform = transforms.Compose([\n",
    " transforms.Resize(226),\n",
    " transforms.CenterCrop(224),\n",
    " transforms.ToTensor(),\n",
    " transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t#  a “pretty printer” for producing aesthetically pleasing representations of your data structures\n",
    "    from pprint import pprint\n",
    "\t#  function call to get trainloader,testloader and classes\n",
    "    trs, ts, classes = get_data(transform=beavernet_transform)\n",
    "\t# show images\n",
    "    show(trs, classes)\n",
    "    pprint(classes)\n",
    "    print('Number of classes:', len(classes))\n",
    "    print(\"Where's the beaver?\")\n",
    "    print(classes.index('beaver'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1\n",
      "[1, 2000] loss: 4.360\n",
      "[1, 4000] loss: 4.036\n",
      "[1, 6000] loss: 3.889\n",
      "[1, 8000] loss: 3.767\n",
      "[1, 10000] loss: 3.698\n",
      "[1, 12000] loss: 3.644\n",
      "Epoch: 2\n",
      "[2, 2000] loss: 3.597\n",
      "[2, 4000] loss: 3.519\n",
      "[2, 6000] loss: 3.487\n",
      "[2, 8000] loss: 3.406\n",
      "[2, 10000] loss: 3.395\n",
      "[2, 12000] loss: 3.375\n",
      "Epoch: 3\n",
      "[3, 2000] loss: 3.379\n",
      "[3, 4000] loss: 3.305\n",
      "[3, 6000] loss: 3.311\n",
      "[3, 8000] loss: 3.236\n",
      "[3, 10000] loss: 3.248\n",
      "[3, 12000] loss: 3.224\n",
      "Epoch: 4\n",
      "[4, 2000] loss: 3.248\n",
      "[4, 4000] loss: 3.199\n",
      "[4, 6000] loss: 3.195\n",
      "[4, 8000] loss: 3.148\n",
      "[4, 10000] loss: 3.163\n",
      "[4, 12000] loss: 3.143\n",
      "Epoch: 5\n",
      "[5, 2000] loss: 3.168\n",
      "[5, 4000] loss: 3.126\n",
      "[5, 6000] loss: 3.124\n",
      "[5, 8000] loss: 3.095\n",
      "[5, 10000] loss: 3.109\n",
      "[5, 12000] loss: 3.098\n",
      "Trained on 12499 images\n",
      "Trying to predict \n",
      "mountain forest seal mushroom\n",
      "Predicted: \n",
      "skyscraper wolf tractor mushroom\n",
      "Test accuracy on 2499 test images: 20 %\n",
      "Model saved in model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Pytorch\\Section2\\train.py\n",
    "\"\"\"\n",
    "Train a custom CNN network using CIFAR100 dataset.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os.path\n",
    "from torchvision import models\n",
    "\n",
    "#from prep import get_data,beavernet_transform,alexnet_transform\n",
    "\n",
    "class BeaverNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Since training AlexNet is time consuming,\n",
    "    we will use a much simpler CNN architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=100):\n",
    "\t\t#-object\n",
    "        super(BeaverNet, self).__init__()\n",
    "\t\t#-2d Convolution 3 rows,6 colums and 5 channels\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "\t\t#-max pooling size- with max value and size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\t\t#-2d Convolution\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\t\t#-Linear-In features or size,out features or size and bias-bool-optional-to relearn additive bias\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 110)\n",
    "        self.fc3 = nn.Linear(110, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\t\t#-conv 1-->relu-->Max pool 2 times to reduce size\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\t\t#-to resize image and output size- -1 for dynamic allocation of size\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "\t\t# - apply relu function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_nn(net, epochs, trainloader, loss_function, optimizer):\n",
    "    \"\"\"\n",
    "    Train net epochs number of times using data from trainloader\n",
    "    and use loss_function and optimizer to get better.\n",
    "    \"\"\"\n",
    "\t#-number of iterations\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch:', epoch+1)\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # Get one batch of both images and labels.\n",
    "            images, classes = data\n",
    "\n",
    "            # Forward pass: predict classes for a given image.\n",
    "            outputs = net(images)\n",
    "\n",
    "            # Calculate the difference between\n",
    "            # what we've predicted and what we should\n",
    "            # predict.\n",
    "            loss = loss_function(outputs, classes)\n",
    "\n",
    "            # Because changes('gradients') are accumulated\n",
    "            # from one iteration to another we need to\n",
    "            # clean up the last ones, so we can propagate\n",
    "            # the ones from this iteration.\n",
    "            # Note: always call it before\n",
    "            # loss.backward() and optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: accumulate changes('gradients')\n",
    "            # that we've learned about in this iteration.\n",
    "            loss.backward()\n",
    "\n",
    "            # Backward pass: propagate changes trough the network.\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                print('[%d, %d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Trained on %d images' % i)\n",
    "\n",
    "def test_nn(net, testloader, classes, batch_size=4):\n",
    "    \"\"\"\n",
    "    Quickly test net on a small amount of data.\n",
    "    \"\"\"\n",
    "    # Get the first image from a test data set\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    print('Trying to predict ')\n",
    "    print(' '.join(['%s' % classes[labels[j]] for j in range(batch_size)]))\n",
    "    # Feed the image to the network and\n",
    "    # get the classified classes.\n",
    "    outputs = net(images)\n",
    "    # Get the most probable classes first.\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print('Predicted: ')\n",
    "    print(' '.join(['%s' % classes[predicted[j]] for j in range(batch_size)]))\n",
    "\n",
    "def test_nn_all(net, testloader):\n",
    "    \"\"\"\n",
    "    Test data on all test dataset, calculate how\n",
    "    much images have been classified correctly.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # When testing we don't need to adjust\n",
    "    # the network parameters, so we can\n",
    "    # turn off accumulating changes('gradients').\n",
    "    # (this will save us memory)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            # Get a single batch of images\n",
    "            # and associated classes.\n",
    "            images, classes = data\n",
    "            # Feed the network with those images\n",
    "            # to check how they will be classified.\n",
    "            outputs = net(images)\n",
    "            # Get the most probable classes first.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Add current number images we process to the total.\n",
    "            total += len(images)\n",
    "            # How much images were classified correctly?\n",
    "            correct += (predicted == classes).sum().item()\n",
    "\n",
    "    print('Test accuracy on %d test images: %d %%' % (i, 100 * correct / total))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from sys import argv\n",
    "    epochs=5\n",
    "    # To train models defined in pytorch\n",
    "    # use get_data(transform=alexnet_transform)\n",
    "    # and get_nn(models.alexnet(num_classes=100))\n",
    "\t#-refer prep.py\n",
    "    train, test, classes=get_data(transform=beavernet_transform)\n",
    "\t#-Beavernet object creation\n",
    "    net=BeaverNet(num_classes=100)\n",
    "\t#-measures log loss-loss will be 0 in ideal scenario\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\t#-optimize using adam algorithm-comparable to best known algo-pass parameters\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "\t#-using train dataset to train model\n",
    "    train_nn(net, epochs, train, loss_function, optimizer)\n",
    "\t#-using test dataset to predict image\n",
    "    test_nn(net, test, classes)\n",
    "\t#-using test dataset to predict image for whole data and find accuracy\n",
    "    test_nn_all(net, test)\n",
    "\t#-save trained model in model.ckpt by serializing it using pickle,state_dict contains all the learned parameters\n",
    "    torch.save(net.state_dict(), 'model.ckpt')\n",
    "    print('Model saved in model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Classification using pretrained AlexNet CNN model:\n",
      "b1.jpg beaver! Most probable classes: beaver(28.480471),marmot(27.411659),polecat, fitch, foulmart, foumart, Mustela putorius(25.649881)\n",
      "b2.jpg beaver! Most probable classes: beaver(28.527224),mink(19.976379),otter(18.768093)\n",
      "b3.jpg beaver! Most probable classes: beaver(21.700571),titi, titi monkey(15.922150),indri, indris, Indri indri, Indri brevicaudatus(15.451862)\n",
      "nob1.jpg not bever! Most probable classes: bull mastiff(26.521837),Rhodesian ridgeback(24.646307),boxer(24.612545)\n",
      "nob2.jpg not bever! Most probable classes: chow, chow chow(15.213093),standard poodle(14.411991),Tibetan terrier, chrysanthemum dog(12.943334)\n",
      "nob3.jpg not bever! Most probable classes: Sussex spaniel(13.593718),tarantula(12.549062),Persian cat(11.599371)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Pytorch\\Section2\\predict.py\n",
    "\"\"\"\n",
    "Classify images using a pre trained AlexNet CNN network\n",
    "as well as a custom CNN model if it's available.\n",
    "\n",
    "Custom CNN model has to be available in model.ckpt file.\n",
    "Generate this file by running ./train.py script.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os.path\n",
    "\n",
    "#from train import BeaverNet\n",
    "#from prep import get_data\n",
    "\n",
    "# Getting the mapping between classes index and\n",
    "# their names.\n",
    "_,_,cifar100_classes=get_data()\n",
    "\n",
    "def get_imgnet_classes():\n",
    "    \"\"\"\n",
    "    Get labels/classes for ImageNet (AlexNet).\n",
    "    Source: https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    "    \"\"\"\n",
    "    return eval(open('C:\\Pytorch\\Section2\\imagenet1000_clsid_to_human.txt').read())\n",
    "\n",
    "def prep_pretrained(imgf):\n",
    "    \"\"\"\n",
    "    Process an image so it can be used with\n",
    "    pre trained models available in PyTorch\n",
    "    (including AlexNet).\n",
    "\n",
    "    imgf - a name of the file to process\n",
    "    \"\"\"\n",
    "    p_transform = transforms.Compose([\n",
    "     transforms.Resize(226),\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img = Image.open(imgf)\n",
    "    new_img=p_transform(img)\n",
    "    return new_img\n",
    "\n",
    "def prep(imgf):\n",
    "    \"\"\"\n",
    "    Process an image to use with our custom\n",
    "    CNN network.\n",
    "    \"\"\"\n",
    "    p_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    img = Image.open(imgf)\n",
    "    new_img=p_transform(img)\n",
    "    return new_img\n",
    "\n",
    "def classify(img_dir, prep, model, classes):\n",
    "    \"\"\"\n",
    "    For each image in img_dir, first process an image\n",
    "    using prep function,  use a an model to\n",
    "    classify it according to classes defined in classes.\n",
    "    \"\"\"\n",
    "\t# os.listdir- returns list of file names\n",
    "    for f in os.listdir(img_dir):\n",
    "        msg=f\n",
    "        # First we need to preprocess an image\n",
    "        # so it will be good fit for our model\n",
    "        ni=prep(os.path.join(img_dir,f))\n",
    "        # Our preparation function will return\n",
    "        # a tensor with data from an image\n",
    "        #\n",
    "        # Tensor is bascily an array.\n",
    "        # If you want to use it with a model\n",
    "        # it has to be in the right \"format\"\n",
    "        # unqueeze(0) means add this tensor\n",
    "        # into an extra array\n",
    "        uni=ni.unsqueeze(0)\n",
    "        # No we're ready to use our mode.\n",
    "        out=model(uni)\n",
    "        # We need to convert our results from\n",
    "        # tensor to an array that we can easily examine.\n",
    "        mout=out.detach().numpy()\n",
    "        # Creating an array with class indexes,\n",
    "        # \"score\" (also called an energy) and name of\n",
    "        # the classess.\n",
    "        # The higher the energy for a give class the more\n",
    "        # probable it is that our image belongs to it.\n",
    "        aao=[]\n",
    "        for i, o in enumerate(mout[0]):\n",
    "            iv='?'\n",
    "            try:\n",
    "                iv=classes[i]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            aao.append((i, o, iv))\n",
    "        # Just sort our array to show most probable classes first.\n",
    "        aao.sort(key=lambda x: x[1], \treverse=True)\n",
    "        if aao[0][2] == 'beaver':\n",
    "            msg+=' beaver!'\n",
    "        else:\n",
    "            #\n",
    "            msg+=' not bever!'\n",
    "        msg+=' Most probable classes: %s' % ','.join([ (aao[ci][2]+'(%f)' % aao[ci][1]) for ci in range(3) ])\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    print('Classification using pretrained AlexNet CNN model:')\n",
    "\t# returns model pre trained on Imagenet\n",
    "    an=models.alexnet(pretrained=True)\n",
    "\t# read given data from a text file\n",
    "    imgnc=get_imgnet_classes()\n",
    "\t\n",
    "    classify('C:\\Pytorch\\Section2\\img_data', prep_pretrained, an, imgnc)\n",
    "    print(' ')\n",
    "    \"\"\"print('Classification our custom CNN model:')\n",
    "    net = BeaverNet(num_classes=100)\n",
    "    if os.path.exists('model.ckpt'):\n",
    "        net.load_state_dict(torch.load('model.ckpt'))\n",
    "        net.eval()\n",
    "    else:\n",
    "        print('No model found! You need to train it first, just run train.py')\n",
    "        exit(1)\n",
    "    classify('C:\\Pytorch\\Section2\\img_data',prep, net, cifar100_classes)*/\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
